{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()\n\n#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","metadata":{"execution":{"iopub.status.busy":"2023-11-27T11:02:45.618853Z","iopub.execute_input":"2023-11-27T11:02:45.619825Z","iopub.status.idle":"2023-11-27T11:02:45.645566Z","shell.execute_reply.started":"2023-11-27T11:02:45.619783Z","shell.execute_reply":"2023-11-27T11:02:45.644444Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44231bfb93e24c4eb6008aec3247033b"}},"metadata":{}}]},{"cell_type":"code","source":"# authenticate WandB for logging metrics\nimport wandb\nwandb.login()\n# ee311bc313381f6bee4c5412a630fdad1175f3c0\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T11:03:21.640371Z","iopub.execute_input":"2023-11-27T11:03:21.641188Z","iopub.status.idle":"2023-11-27T11:03:29.315087Z","shell.execute_reply.started":"2023-11-27T11:03:21.641156Z","shell.execute_reply":"2023-11-27T11:03:29.314166Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"!pip install trl transformers accelerate git+https://github.com/huggingface/peft.git -Uqqq\n!pip install datasets bitsandbytes einops wandb -Uqqq","metadata":{"execution":{"iopub.status.busy":"2023-11-27T11:03:31.863322Z","iopub.execute_input":"2023-11-27T11:03:31.864169Z","iopub.status.idle":"2023-11-27T11:04:30.354487Z","shell.execute_reply.started":"2023-11-27T11:03:31.864135Z","shell.execute_reply":"2023-11-27T11:04:30.353210Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.19.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\n\nimport torch\nfrom datasets import load_dataset\nfrom peft import LoraConfig, get_peft_model, PeftConfig, PeftModel, prepare_model_for_kbit_training\nfrom transformers import (AutoModelForCausalLM, AutoTokenizer,\n                          BitsAndBytesConfig, HfArgumentParser,\n                          TrainingArguments,GenerationConfig, logging, pipeline)\nfrom trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2023-11-27T11:04:30.356970Z","iopub.execute_input":"2023-11-27T11:04:30.357944Z","iopub.status.idle":"2023-11-27T11:04:50.470625Z","shell.execute_reply.started":"2023-11-27T11:04:30.357902Z","shell.execute_reply":"2023-11-27T11:04:50.469556Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = \"Intel/neural-chat-7b-v3-1\" # sharded Mistral-7b model\ndataset_name = \"vibhorag101/phr_mental_health_dataset\"\nnew_model = \"Intel-10000D-chat-hf-phr_mental_therapy\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,            # load model in 4-bit precision\n    bnb_4bit_quant_type=\"nf4\",    # pre-trained model should be quantized in 4-bit NF format\n    bnb_4bit_use_double_quant=True, # Using double quantization as mentioned in QLoRA paper\n    bnb_4bit_compute_dtype=torch.bfloat16, # During computation, pre-trained model should be loaded in BF16 format\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config, # Use bitsandbytes config\n    device_map=\"auto\",  # Specifying device_map=\"auto\" so that HF Accelerate will determine which GPU to put each layer of the model on\n    trust_remote_code=True, # Set trust_remote_code=True to use Mistral-7b model with custom code\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T11:05:12.533008Z","iopub.execute_input":"2023-11-27T11:05:12.533759Z","iopub.status.idle":"2023-11-27T11:07:32.288637Z","shell.execute_reply.started":"2023-11-27T11:05:12.533727Z","shell.execute_reply":"2023-11-27T11:07:32.287503Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1ba001a0b4e4349b0726fbaa3c4a062"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"204b7a5392184f64921ec0803322d12a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9a1310c58fc47f1aee481a69920a393"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0372a259605a4593a3f6961d73efe772"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00002-of-00002.bin:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31de6fc683cf4e04b7c7f068c16ebad6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d50508e593994fe98eefb3af56c64589"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a955ae6c8dcc415a9084a1919d06df2a"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = load_dataset(dataset_name, split=\"train\")\ndataset = dataset.shuffle().select(range(10000))\ndataset.train_test_split(test_size=0.05)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T11:07:32.290834Z","iopub.execute_input":"2023-11-27T11:07:32.291776Z","iopub.status.idle":"2023-11-27T11:07:47.625774Z","shell.execute_reply.started":"2023-11-27T11:07:32.291735Z","shell.execute_reply":"2023-11-27T11:07:47.624841Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/460 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfb66baf4d194cd4a3240ed2e820807c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d52bfebc8754dcf9eee801ddc4ee4a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/211M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"134df843fd544e098eda5e7ef22bd74c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d545088f5f344f68e8aaf804954280d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/99086 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ea4460a73c342738b670c478369da91"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text'],\n        num_rows: 9500\n    })\n    test: Dataset({\n        features: ['text'],\n        num_rows: 500\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(dataset['text'][1])","metadata":{"execution":{"iopub.status.busy":"2023-11-27T11:07:47.627104Z","iopub.execute_input":"2023-11-27T11:07:47.627796Z","iopub.status.idle":"2023-11-27T11:07:47.752924Z","shell.execute_reply.started":"2023-11-27T11:07:47.627756Z","shell.execute_reply":"2023-11-27T11:07:47.751939Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<s>[INST] <<SYS>>\nYou are a helpful and joyous mental therapy assistant. Always answer as helpfully and cheerfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.Please ensure that your responses are socially unbiased and positive in nature.\n\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n<</SYS>\n\nHi . I've been feeling a bit lonely lately, and it's making me question my sense of responsibility in my personal relationships. [/INST] Hi . I'm here to support you. Can you tell me more about why you're feeling lonely and how it relates to your sense of responsibility? </s><s>[INST] Thanks.  Well, I've been noticing that I've been spending more time alone and it's starting to affect my mood. I feel like I'm responsible for maintaining strong connections with the people in my life, but lately, I haven't been doing a good job at it. [/INST] It sounds like you are aware of this shift in your relationships and the impact it's having on your overall well-being. Can you share what might have contributed to this change? </s><s>[INST] I think part of it has to do with my work schedule becoming busier, and I've been prioritizing my responsibilities there. But I also admit that I haven't been putting in the effort to reach out and connect with my loved ones. [/INST] It's great that you're able to recognize these factors. It's common to struggle with finding a balance between work and personal life. How do you feel when you think about not being as present in your relationships as you want to be? </s><s>[INST] It makes me feel guilty and sad. I value my relationships, and it hurts to think that I may be neglecting them. I want to be there for my loved ones, but sometimes it feels like there aren't enough hours in the day. [/INST] Your feelings of guilt and sadness are valid. It's important to remember that you're not alone in experiencing these challenges. We all have limitations, and finding a balance can be tough. Have you talked to your loved ones about how you've been feeling? </s><s>[INST] Not yet, but I've been thinking about it. I want to apologize to them for not being as present as I would like to be. It's just a matter of finding the right time and approach. [/INST] That sounds like a positive step.  Open communication is crucial in nurturing relationships. It can be helpful to express your genuine intentions and discuss how you can work together to strengthen your connections. </s><s>[INST] You're right.  I believe that by acknowledging my responsibility in maintaining these relationships and having open conversations, I can start working towards a healthier balance and deepen my connections with my loved ones. [/INST] It's wonderful to hear your optimism.  Remember, personal growth takes time and effort. Being aware of the changes you want to make is the first step. How can you start incorporating small actions to reach out and reconnect with your loved ones? </s><s>[INST] I can begin by setting aside specific times each week to spend quality time with them, whether it's having a shared meal or engaging in activities we enjoy together. I can also make an effort to reach out regularly through calls or messages to show my love and support. [/INST] Those are great ideas.  Taking small, consistent steps can make a significant difference. Remember that personal relationships require effort from both sides. How can you encourage them to also play an active role in maintaining strong connections? </s><s>[INST] I think by expressing my desire for a deeper connection with them and sharing my own struggles, I can encourage open dialogue. Making them feel comfortable enough to share their thoughts and feelings will help us build a stronger foundation together. [/INST] That's a wonderful approach.  By fostering a safe and open space for communication, you can create opportunities for growth and understanding within your relationships. Remember that everyone faces their own challenges, and by supporting each other, you can navigate through them together. </s><s>[INST] I really appreciate your guidance.  I feel more motivated and supported now. I will make a conscious effort to be there for my loved ones and prioritize our connection. [/INST] It's my pleasure.  Remember to be patient and kind to yourself throughout this journey. Change takes time, and setbacks are a natural part of the process. Celebrate your small victories along the way, and feel free to reach out whenever you need support. You're on the path to nurturing healthier and more fulfilling relationships. </s>\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\nlora_alpha = 32 # scaling factor for the weight matrices\nlora_dropout = 0.05 # dropout probability of the LoRA layers\nlora_rank = 16 # dimension of the low-rank matrices\n\npeft_config = LoraConfig(\n    lora_alpha=lora_alpha,\n    lora_dropout=lora_dropout,\n    r=lora_rank,\n    bias=\"none\",  # setting to 'none' for only training weight params instead of biases\n    task_type=\"CAUSAL_LM\",\n    \n)\n\npeft_model = get_peft_model(model, peft_config)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T11:07:47.754878Z","iopub.execute_input":"2023-11-27T11:07:47.755179Z","iopub.status.idle":"2023-11-27T11:07:48.573623Z","shell.execute_reply.started":"2023-11-27T11:07:47.755153Z","shell.execute_reply":"2023-11-27T11:07:48.572591Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"output_dir = \"./Intel-10000D-chat-hf-phr_mental_therapy\"\nper_device_train_batch_size = 2 # reduce batch size by 2x only if out-of-memory error\ngradient_accumulation_steps = 1  # increase gradient accumulation steps by  2x only if batch size is reduced\noptim = \"paged_adamw_32bit\" # activates the paging for better memory management\nsave_strategy=\"steps\" # checkpoint save strategy to adopt during training\nsave_steps = 10 # number of updates steps before two checkpoint saves\nlogging_steps = 10  # number of update steps between two logs if logging_strategy=\"steps\"\nlearning_rate = 2e-4  # learning rate for AdamW optimizer\nmax_grad_norm = 0.3 # maximum gradient norm (for gradient clipping)\nmax_steps = -1      # training will happen for automatic steps\nwarmup_ratio = 0.03 # number of steps used for a linear warmup from 0 to learning_rate\nlr_scheduler_type = \"cosine\"  # learning rate scheduler\nnum_train_epochs = 2\nper_device_eval_batch_size = 2\nmax_seq_length=512\n\ntraining_arguments = TrainingArguments(\n    output_dir=output_dir,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    num_train_epochs= num_train_epochs,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    fp16=True,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=True,\n    lr_scheduler_type=lr_scheduler_type,\n    push_to_hub=True,\n    \n)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T11:08:11.101227Z","iopub.execute_input":"2023-11-27T11:08:11.101645Z","iopub.status.idle":"2023-11-27T11:08:11.113933Z","shell.execute_reply.started":"2023-11-27T11:08:11.101612Z","shell.execute_reply":"2023-11-27T11:08:11.112763Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)\nmodel.config.use_cache = False\nmodel.config.pretraining_tp = 1\n\n# # Load LLaMA tokenizer\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,use_fast=False,add_eos_token=True)\ntokenizer.pad_token_id = 18610","metadata":{"execution":{"iopub.status.busy":"2023-11-27T11:08:13.303791Z","iopub.execute_input":"2023-11-27T11:08:13.304160Z","iopub.status.idle":"2023-11-27T11:09:19.423862Z","shell.execute_reply.started":"2023-11-27T11:08:13.304129Z","shell.execute_reply":"2023-11-27T11:09:19.423028Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"238f6c9e0a6544cbbcb193b804443685"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer_config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d714ece337b4fd5bb479113f9c0ec60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22eb443e814c4264b8e6188b626ac9fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/145 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f3dbf590c794072b1a2a97f51fb48f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"629bae03cafc4cdf82b90951cbaa6685"}},"metadata":{}}]},{"cell_type":"code","source":"#Set supervised fine-tuning parameters\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    peft_config=peft_config,\n    dataset_text_field=\"text\",\n    max_seq_length=256,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing=False,\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T11:09:19.425535Z","iopub.execute_input":"2023-11-27T11:09:19.425847Z","iopub.status.idle":"2023-11-27T11:10:49.523237Z","shell.execute_reply.started":"2023-11-27T11:09:19.425820Z","shell.execute_reply":"2023-11-27T11:10:49.522255Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e01f44aa01e7407a8de8a6459ef945f3"}},"metadata":{}}]},{"cell_type":"code","source":"# upcasting the layer norms in torch.bfloat16 for more stable training\nfor name, module in trainer.model.named_modules():\n    if \"norm\" in name:\n        module = module.to(torch.bfloat16)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T11:10:49.524397Z","iopub.execute_input":"2023-11-27T11:10:49.524686Z","iopub.status.idle":"2023-11-27T11:10:49.535944Z","shell.execute_reply.started":"2023-11-27T11:10:49.524660Z","shell.execute_reply":"2023-11-27T11:10:49.535164Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.config.use_cache = False\ntrainer.train()\ntrainer.model.save_pretrained(new_model)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T11:10:49.538132Z","iopub.execute_input":"2023-11-27T11:10:49.538456Z","iopub.status.idle":"2023-11-27T12:20:51.874916Z","shell.execute_reply.started":"2023-11-27T11:10:49.538431Z","shell.execute_reply":"2023-11-27T12:20:51.872371Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mr1ajayakumaran1751994\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231127_111053-phjolz4s</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/r1ajayakumaran1751994/huggingface/runs/phjolz4s' target=\"_blank\">fiery-planet-22</a></strong> to <a href='https://wandb.ai/r1ajayakumaran1751994/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/r1ajayakumaran1751994/huggingface' target=\"_blank\">https://wandb.ai/r1ajayakumaran1751994/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/r1ajayakumaran1751994/huggingface/runs/phjolz4s' target=\"_blank\">https://wandb.ai/r1ajayakumaran1751994/huggingface/runs/phjolz4s</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2541' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 2541/10000 1:09:19 < 3:23:39, 0.61 it/s, Epoch 0.51/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.940500</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.728600</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.467000</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>2.129000</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.656700</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.027500</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.753000</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.694200</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.661400</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.662500</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.604500</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.572700</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.565000</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.577800</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.542700</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.522600</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.560300</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.570000</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.539800</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.540400</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.556100</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.541100</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.526600</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.506600</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.528600</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.544500</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.511400</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.519200</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.544200</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.519200</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.508700</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.490100</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.493800</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.461800</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.451800</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.451600</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.463400</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.490300</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.444800</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.438800</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.455200</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.428000</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.466700</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.439400</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.418700</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.433800</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.440100</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.441600</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.415400</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.419300</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.459300</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.439600</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.468400</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.440300</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.445800</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.450500</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.437100</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.401900</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.451500</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.446400</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.417500</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.417700</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.425600</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.429400</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.439500</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.409800</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.428900</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.427200</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.454700</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.449600</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.454000</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.435100</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.432000</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.430400</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.439300</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.403600</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.442500</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.400500</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.443800</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.433400</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.422800</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.419100</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.422000</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.416900</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.410600</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.441000</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.427700</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.445700</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.437900</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.436400</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.427700</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.427900</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>0.419400</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.419200</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.418900</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>0.408600</td>\n    </tr>\n    <tr>\n      <td>970</td>\n      <td>0.438600</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>0.431100</td>\n    </tr>\n    <tr>\n      <td>990</td>\n      <td>0.399700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.446500</td>\n    </tr>\n    <tr>\n      <td>1010</td>\n      <td>0.397000</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>0.414200</td>\n    </tr>\n    <tr>\n      <td>1030</td>\n      <td>0.454000</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>0.447400</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.402900</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>0.432300</td>\n    </tr>\n    <tr>\n      <td>1070</td>\n      <td>0.412500</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>0.445400</td>\n    </tr>\n    <tr>\n      <td>1090</td>\n      <td>0.443200</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.401200</td>\n    </tr>\n    <tr>\n      <td>1110</td>\n      <td>0.427100</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>0.434800</td>\n    </tr>\n    <tr>\n      <td>1130</td>\n      <td>0.402900</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>0.412500</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.432000</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>0.430800</td>\n    </tr>\n    <tr>\n      <td>1170</td>\n      <td>0.428700</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>0.434600</td>\n    </tr>\n    <tr>\n      <td>1190</td>\n      <td>0.433300</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.432500</td>\n    </tr>\n    <tr>\n      <td>1210</td>\n      <td>0.396300</td>\n    </tr>\n    <tr>\n      <td>1220</td>\n      <td>0.423800</td>\n    </tr>\n    <tr>\n      <td>1230</td>\n      <td>0.425100</td>\n    </tr>\n    <tr>\n      <td>1240</td>\n      <td>0.434800</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.423800</td>\n    </tr>\n    <tr>\n      <td>1260</td>\n      <td>0.415300</td>\n    </tr>\n    <tr>\n      <td>1270</td>\n      <td>0.426500</td>\n    </tr>\n    <tr>\n      <td>1280</td>\n      <td>0.442700</td>\n    </tr>\n    <tr>\n      <td>1290</td>\n      <td>0.410600</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.431700</td>\n    </tr>\n    <tr>\n      <td>1310</td>\n      <td>0.434900</td>\n    </tr>\n    <tr>\n      <td>1320</td>\n      <td>0.406600</td>\n    </tr>\n    <tr>\n      <td>1330</td>\n      <td>0.405000</td>\n    </tr>\n    <tr>\n      <td>1340</td>\n      <td>0.416800</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.388800</td>\n    </tr>\n    <tr>\n      <td>1360</td>\n      <td>0.395200</td>\n    </tr>\n    <tr>\n      <td>1370</td>\n      <td>0.407000</td>\n    </tr>\n    <tr>\n      <td>1380</td>\n      <td>0.406400</td>\n    </tr>\n    <tr>\n      <td>1390</td>\n      <td>0.397500</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.417200</td>\n    </tr>\n    <tr>\n      <td>1410</td>\n      <td>0.414100</td>\n    </tr>\n    <tr>\n      <td>1420</td>\n      <td>0.405700</td>\n    </tr>\n    <tr>\n      <td>1430</td>\n      <td>0.425800</td>\n    </tr>\n    <tr>\n      <td>1440</td>\n      <td>0.434000</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.394400</td>\n    </tr>\n    <tr>\n      <td>1460</td>\n      <td>0.411700</td>\n    </tr>\n    <tr>\n      <td>1470</td>\n      <td>0.432300</td>\n    </tr>\n    <tr>\n      <td>1480</td>\n      <td>0.425400</td>\n    </tr>\n    <tr>\n      <td>1490</td>\n      <td>0.412700</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.400100</td>\n    </tr>\n    <tr>\n      <td>1510</td>\n      <td>0.404200</td>\n    </tr>\n    <tr>\n      <td>1520</td>\n      <td>0.427500</td>\n    </tr>\n    <tr>\n      <td>1530</td>\n      <td>0.412300</td>\n    </tr>\n    <tr>\n      <td>1540</td>\n      <td>0.405800</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.459100</td>\n    </tr>\n    <tr>\n      <td>1560</td>\n      <td>0.404400</td>\n    </tr>\n    <tr>\n      <td>1570</td>\n      <td>0.409400</td>\n    </tr>\n    <tr>\n      <td>1580</td>\n      <td>0.430300</td>\n    </tr>\n    <tr>\n      <td>1590</td>\n      <td>0.386000</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.396100</td>\n    </tr>\n    <tr>\n      <td>1610</td>\n      <td>0.397900</td>\n    </tr>\n    <tr>\n      <td>1620</td>\n      <td>0.423700</td>\n    </tr>\n    <tr>\n      <td>1630</td>\n      <td>0.413100</td>\n    </tr>\n    <tr>\n      <td>1640</td>\n      <td>0.459100</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.409700</td>\n    </tr>\n    <tr>\n      <td>1660</td>\n      <td>0.390000</td>\n    </tr>\n    <tr>\n      <td>1670</td>\n      <td>0.400700</td>\n    </tr>\n    <tr>\n      <td>1680</td>\n      <td>0.449300</td>\n    </tr>\n    <tr>\n      <td>1690</td>\n      <td>0.419600</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.450200</td>\n    </tr>\n    <tr>\n      <td>1710</td>\n      <td>0.426200</td>\n    </tr>\n    <tr>\n      <td>1720</td>\n      <td>0.412300</td>\n    </tr>\n    <tr>\n      <td>1730</td>\n      <td>0.411300</td>\n    </tr>\n    <tr>\n      <td>1740</td>\n      <td>0.431600</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.387700</td>\n    </tr>\n    <tr>\n      <td>1760</td>\n      <td>0.410000</td>\n    </tr>\n    <tr>\n      <td>1770</td>\n      <td>0.409300</td>\n    </tr>\n    <tr>\n      <td>1780</td>\n      <td>0.397000</td>\n    </tr>\n    <tr>\n      <td>1790</td>\n      <td>0.400500</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.430300</td>\n    </tr>\n    <tr>\n      <td>1810</td>\n      <td>0.443700</td>\n    </tr>\n    <tr>\n      <td>1820</td>\n      <td>0.386800</td>\n    </tr>\n    <tr>\n      <td>1830</td>\n      <td>0.393200</td>\n    </tr>\n    <tr>\n      <td>1840</td>\n      <td>0.419500</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>0.423300</td>\n    </tr>\n    <tr>\n      <td>1860</td>\n      <td>0.414800</td>\n    </tr>\n    <tr>\n      <td>1870</td>\n      <td>0.407100</td>\n    </tr>\n    <tr>\n      <td>1880</td>\n      <td>0.416000</td>\n    </tr>\n    <tr>\n      <td>1890</td>\n      <td>0.404700</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.427000</td>\n    </tr>\n    <tr>\n      <td>1910</td>\n      <td>0.424100</td>\n    </tr>\n    <tr>\n      <td>1920</td>\n      <td>0.403000</td>\n    </tr>\n    <tr>\n      <td>1930</td>\n      <td>0.401800</td>\n    </tr>\n    <tr>\n      <td>1940</td>\n      <td>0.432800</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>0.396400</td>\n    </tr>\n    <tr>\n      <td>1960</td>\n      <td>0.423400</td>\n    </tr>\n    <tr>\n      <td>1970</td>\n      <td>0.419300</td>\n    </tr>\n    <tr>\n      <td>1980</td>\n      <td>0.397100</td>\n    </tr>\n    <tr>\n      <td>1990</td>\n      <td>0.436800</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.400500</td>\n    </tr>\n    <tr>\n      <td>2010</td>\n      <td>0.431100</td>\n    </tr>\n    <tr>\n      <td>2020</td>\n      <td>0.430200</td>\n    </tr>\n    <tr>\n      <td>2030</td>\n      <td>0.389800</td>\n    </tr>\n    <tr>\n      <td>2040</td>\n      <td>0.414100</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>0.402300</td>\n    </tr>\n    <tr>\n      <td>2060</td>\n      <td>0.395600</td>\n    </tr>\n    <tr>\n      <td>2070</td>\n      <td>0.420200</td>\n    </tr>\n    <tr>\n      <td>2080</td>\n      <td>0.436100</td>\n    </tr>\n    <tr>\n      <td>2090</td>\n      <td>0.395400</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>0.370400</td>\n    </tr>\n    <tr>\n      <td>2110</td>\n      <td>0.430600</td>\n    </tr>\n    <tr>\n      <td>2120</td>\n      <td>0.425500</td>\n    </tr>\n    <tr>\n      <td>2130</td>\n      <td>0.407900</td>\n    </tr>\n    <tr>\n      <td>2140</td>\n      <td>0.408800</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>0.392000</td>\n    </tr>\n    <tr>\n      <td>2160</td>\n      <td>0.393000</td>\n    </tr>\n    <tr>\n      <td>2170</td>\n      <td>0.393800</td>\n    </tr>\n    <tr>\n      <td>2180</td>\n      <td>0.399000</td>\n    </tr>\n    <tr>\n      <td>2190</td>\n      <td>0.416100</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>0.430500</td>\n    </tr>\n    <tr>\n      <td>2210</td>\n      <td>0.408600</td>\n    </tr>\n    <tr>\n      <td>2220</td>\n      <td>0.428500</td>\n    </tr>\n    <tr>\n      <td>2230</td>\n      <td>0.409400</td>\n    </tr>\n    <tr>\n      <td>2240</td>\n      <td>0.412200</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>0.424500</td>\n    </tr>\n    <tr>\n      <td>2260</td>\n      <td>0.415900</td>\n    </tr>\n    <tr>\n      <td>2270</td>\n      <td>0.445200</td>\n    </tr>\n    <tr>\n      <td>2280</td>\n      <td>0.387900</td>\n    </tr>\n    <tr>\n      <td>2290</td>\n      <td>0.428700</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>0.426100</td>\n    </tr>\n    <tr>\n      <td>2310</td>\n      <td>0.424900</td>\n    </tr>\n    <tr>\n      <td>2320</td>\n      <td>0.406100</td>\n    </tr>\n    <tr>\n      <td>2330</td>\n      <td>0.431200</td>\n    </tr>\n    <tr>\n      <td>2340</td>\n      <td>0.422200</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>0.411700</td>\n    </tr>\n    <tr>\n      <td>2360</td>\n      <td>0.436800</td>\n    </tr>\n    <tr>\n      <td>2370</td>\n      <td>0.415200</td>\n    </tr>\n    <tr>\n      <td>2380</td>\n      <td>0.373200</td>\n    </tr>\n    <tr>\n      <td>2390</td>\n      <td>0.414400</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>0.394300</td>\n    </tr>\n    <tr>\n      <td>2410</td>\n      <td>0.430300</td>\n    </tr>\n    <tr>\n      <td>2420</td>\n      <td>0.436600</td>\n    </tr>\n    <tr>\n      <td>2430</td>\n      <td>0.423900</td>\n    </tr>\n    <tr>\n      <td>2440</td>\n      <td>0.421400</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>0.439800</td>\n    </tr>\n    <tr>\n      <td>2460</td>\n      <td>0.403300</td>\n    </tr>\n    <tr>\n      <td>2470</td>\n      <td>0.435000</td>\n    </tr>\n    <tr>\n      <td>2480</td>\n      <td>0.398200</td>\n    </tr>\n    <tr>\n      <td>2490</td>\n      <td>0.410700</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.384500</td>\n    </tr>\n    <tr>\n      <td>2510</td>\n      <td>0.382500</td>\n    </tr>\n    <tr>\n      <td>2520</td>\n      <td>0.421900</td>\n    </tr>\n    <tr>\n      <td>2530</td>\n      <td>0.405700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 441\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:668\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    667\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[0;32m--> 668\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:471] . PytorchStreamWriter failed writing file data/195: file write failed","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_pretrained(new_model)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:280\u001b[0m, in \u001b[0;36mSFTTrainer.train\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trl_activate_neftune(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[0;32m--> 280\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# After training we make sure to retrieve back the original forward pass method\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# for the embedding layer by removing the forward post hook.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneftune_noise_alpha \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer_supports_neftune:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1546\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1545\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1546\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1553\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1922\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1922\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1924\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2282\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2279\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2387\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2379\u001b[0m         smp\u001b[38;5;241m.\u001b[39msave(\n\u001b[1;32m   2380\u001b[0m             opt_state_dict,\n\u001b[1;32m   2381\u001b[0m             os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, OPTIMIZER_NAME),\n\u001b[1;32m   2382\u001b[0m             partial\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2383\u001b[0m             v3\u001b[38;5;241m=\u001b[39msmp\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mshard_optimizer_state,\n\u001b[1;32m   2384\u001b[0m         )\n\u001b[1;32m   2385\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfsdp \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_enabled):\n\u001b[1;32m   2386\u001b[0m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[0;32m-> 2387\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2389\u001b[0m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[1;32m   2390\u001b[0m is_deepspeed_custom_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   2391\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[1;32m   2392\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:291\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:337] . unexpected pos 22977792 vs 22977680"],"ename":"RuntimeError","evalue":"[enforce fail at inline_container.cc:337] . unexpected pos 22977792 vs 22977680","output_type":"error"},{"name":"stderr","text":"--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2023-11-27T12:53:08.833616Z","iopub.execute_input":"2023-11-27T12:53:08.834047Z","iopub.status.idle":"2023-11-27T12:53:09.852774Z","shell.execute_reply.started":"2023-11-27T12:53:08.834014Z","shell.execute_reply":"2023-11-27T12:53:09.851366Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x785584135900>> (for pre_run_cell):\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:441\u001b[0m, in \u001b[0;36m_WandbInit._resume_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    440\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresuming backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 441\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:657\u001b[0m, in \u001b[0;36mInterfaceBase.publish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m     resume \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mResumeRequest()\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_resume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:353\u001b[0m, in \u001b[0;36mInterfaceShared._publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_resume\u001b[39m(\u001b[38;5;28mself\u001b[39m, resume: pb\u001b[38;5;241m.\u001b[39mResumeRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(resume\u001b[38;5;241m=\u001b[39mresume)\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"],"ename":"BrokenPipeError","evalue":"[Errno 32] Broken pipe","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3688\u001b[0m, in \u001b[0;36mTrainer.push_to_hub\u001b[0;34m(self, commit_message, blocking, **kwargs)\u001b[0m\n\u001b[1;32m   3684\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_hf_repo()\n\u001b[1;32m   3686\u001b[0m \u001b[38;5;66;03m# Needs to be executed on all processes for TPU training, but will only save on the processed determined by\u001b[39;00m\n\u001b[1;32m   3687\u001b[0m \u001b[38;5;66;03m# self.args.should_save.\u001b[39;00m\n\u001b[0;32m-> 3688\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_internal_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3690\u001b[0m \u001b[38;5;66;03m# Only push from one node.\u001b[39;00m\n\u001b[1;32m   3691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_world_process_zero():\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2843\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2840\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\u001b[38;5;241m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   2842\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2843\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;66;03m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _internal_call:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2901\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   2899\u001b[0m             torch\u001b[38;5;241m.\u001b[39msave(state_dict, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n\u001b[1;32m   2900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2902\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_serialization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_safetensors\u001b[49m\n\u001b[1;32m   2903\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2906\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:194\u001b[0m, in \u001b[0;36mPeftModel.save_pretrained\u001b[0;34m(self, save_directory, safe_serialization, selected_adapters, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou passed an invalid `selected_adapters` arguments, current supported adapter names are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_adapters\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[1;32m    193\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_directory, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_or_update_model_card\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m adapter_name \u001b[38;5;129;01min\u001b[39;00m selected_adapters:\n\u001b[1;32m    197\u001b[0m     peft_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config[adapter_name]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:743\u001b[0m, in \u001b[0;36mPeftModel.create_or_update_model_card\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m    740\u001b[0m     lines\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframework_block_heading\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m- PEFT \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    742\u001b[0m card\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lines)\n\u001b[0;32m--> 743\u001b[0m \u001b[43mcard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/repocard.py:131\u001b[0m, in \u001b[0;36mRepoCard.save\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    129\u001b[0m filepath\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Preserve newlines as in the existing file.\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    132\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n","\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"],"ename":"OSError","evalue":"[Errno 28] No space left on device","output_type":"error"},{"name":"stdout","text":"Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x785584135900>> (for post_run_cell):\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/wandb_init.py:436\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    435\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface.py:649\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    648\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py:349\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 349\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n","\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"],"ename":"BrokenPipeError","evalue":"[Errno 32] Broken pipe","output_type":"error"}]},{"cell_type":"markdown","source":"# Merging as Single without Adapters","metadata":{}},{"cell_type":"code","source":"# Reload model in FP16 and merge it with LoRA weights\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    low_cpu_mem_usage=True,\n    return_dict=True,\n    torch_dtype=torch.float16,\n    device_map=\"cpu\", ## device map = \"cpu\", for merging on cpu\n)\nmodel = PeftModel.from_pretrained(base_model, new_model)\nmodel = model.merge_and_unload()\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,use_fast=False,add_eos_token=True)\ntokenizer.pad_token_id = 18610\n\n### Old version tokeniser, can't generate eos token\n# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n# tokenizer.pad_token = tokenizer.eos_token\n# tokenizer.padding_side = \"right\"\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-27T12:20:51.877833Z","iopub.status.idle":"2023-11-27T12:20:51.878212Z","shell.execute_reply.started":"2023-11-27T12:20:51.878022Z","shell.execute_reply":"2023-11-27T12:20:51.878041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## for inference without merging qlora weights with original\nbase_model = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=device_map\n)\nmodel = PeftModel.from_pretrained(base_model, new_model)\ntokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,use_fast=False,add_eos_token=True)\ntokenizer.pad_token_id = 18610","metadata":{"execution":{"iopub.status.busy":"2023-11-27T12:20:51.880038Z","iopub.status.idle":"2023-11-27T12:20:51.880479Z","shell.execute_reply.started":"2023-11-27T12:20:51.880257Z","shell.execute_reply":"2023-11-27T12:20:51.880274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.push_to_hub(new_model, use_temp_dir=False)\ntokenizer.push_to_hub(new_model, use_temp_dir=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-27T12:20:51.881716Z","iopub.status.idle":"2023-11-27T12:20:51.882072Z","shell.execute_reply.started":"2023-11-27T12:20:51.881899Z","shell.execute_reply":"2023-11-27T12:20:51.881916Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 705, in handle_request_pause\n    logger.info(\"stopping system metrics thread\")\nMessage: 'stopping system metrics thread'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 706, in handle_request_pause\n    self._system_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 203, in finish\n    logger.info(\"Stopping system monitor\")\nMessage: 'Stopping system monitor'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 179, in _start\n    logger.debug(\"Finished system metrics aggregation loop\")\nMessage: 'Finished system metrics aggregation loop'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 706, in handle_request_pause\n    self._system_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n    asset.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/cpu.py\", line 163, in finish\n    self.metrics_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n    logger.info(f\"Joined {thread_name} monitor\")\nMessage: 'Joined cpu monitor'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 183, in _start\n    logger.debug(\"Publishing last batch of metrics\")\nMessage: 'Publishing last batch of metrics'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 706, in handle_request_pause\n    self._system_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n    asset.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/disk.py\", line 210, in finish\n    self.metrics_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n    logger.info(f\"Joined {thread_name} monitor\")\nMessage: 'Joined disk monitor'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 706, in handle_request_pause\n    self._system_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n    asset.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/gpu.py\", line 388, in finish\n    self.metrics_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n    logger.info(f\"Joined {thread_name} monitor\")\nMessage: 'Joined gpu monitor'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 706, in handle_request_pause\n    self._system_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n    asset.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/memory.py\", line 152, in finish\n    self.metrics_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n    logger.info(f\"Joined {thread_name} monitor\")\nMessage: 'Joined memory monitor'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 100, in _run\n    self._process(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 279, in _process\n    self._hm.handle(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 138, in handle\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 148, in handle_request\n    handler(record)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 706, in handle_request_pause\n    self._system_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/system_monitor.py\", line 206, in finish\n    asset.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/network.py\", line 96, in finish\n    self.metrics_monitor.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/system/assets/interfaces.py\", line 202, in finish\n    logger.info(f\"Joined {thread_name} monitor\")\nMessage: 'Joined network monitor'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n    self._sm.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1536, in finish\n    logger.info(\"shutting down sender\")\nMessage: 'shutting down sender'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 282, in _finish\n    self._hm.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/handler.py\", line 866, in finish\n    logger.info(\"shutting down handler\")\nMessage: 'shutting down handler'\nArguments: ()\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/api.py\", line 199, in run\n    self.dispatch_events(self.event_queue, self.timeout)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/observers/api.py\", line 368, in dispatch_events\n    handler.dispatch(event)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/vendor/watchdog_0_9_0/wandb_watchdog/events.py\", line 454, in dispatch\n    _method_map[event_type](event)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/filesync/dir_watcher.py\", line 271, in _on_file_created\n    logger.info(\"file/dir created: %s\", event.src_path)\nMessage: 'file/dir created: %s'\nArguments: ('/kaggle/working/wandb/run-20231127_111053-phjolz4s/files/output.log',)\n--- Logging error ---\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1104, in emit\n    self.flush()\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 1084, in flush\n    self.stream.flush()\nOSError: [Errno 28] No space left on device\nCall stack:\n  File \"/opt/conda/lib/python3.10/threading.py\", line 973, in _bootstrap\n    self._bootstrap_inner()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/service/streams.py\", line 48, in run\n    self._target(**self._kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 174, in wandb_internal\n    logger.error(f\"Thread {thread.name}:\", exc_info=exc_info)\nMessage: 'Thread SenderThread:'\nArguments: ()\nThread SenderThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 49, in run\n    self._run()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py\", line 101, in _run\n    self._finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/internal.py\", line 331, in _finish\n    self._sm.finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1539, in finish\n    self._output_raw_finish()\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1199, in _output_raw_finish\n    self._output_raw_flush(stream)\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/internal/sender.py\", line 1246, in _output_raw_flush\n    self._output_raw_file.write(data.encode(\"utf-8\"))\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/filesystem.py\", line 128, in write\n    super().write(b\"\\n\".join(ret) + b\"\\n\")\n  File \"/opt/conda/lib/python3.10/site-packages/wandb/sdk/lib/filesystem.py\", line 95, in write\n    self.f.flush()\nOSError: [Errno 28] No space left on device\nwandb: ERROR Internal wandb error: file data was not synced\n","output_type":"stream"}]},{"cell_type":"code","source":"logging.set_verbosity(logging.CRITICAL)\nSYSTEM_PROMPT = \"You are a helpful and joyous mental therapy assistant. Always answer as helpfully and cheerfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.If you don't know the answer to a question, please don't share false information. Always try to be as cheerfull as possible\"\n# Run text generation pipeline with our next model\nprompt = \"I am feeling suicidal.I have lost a lot of money in gambling. The money I used was taken as a loan\"\npipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=1000,temperature=0.9)\nresult = pipe(f\"<s>[INST]<<SYS>>{SYSTEM_PROMPT}<</SYS>> {prompt} [/INST]\")\nprint(result[0]['generated_text'])","metadata":{},"execution_count":null,"outputs":[]}]}